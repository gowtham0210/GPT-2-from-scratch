{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVTPcnAP7PloMU2vmxyuoV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowtham0210/GPT-2-from-scratch/blob/main/GPT_2_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing a GTP Model from scratch to Generate Text"
      ],
      "metadata": {
        "id": "pxo0GbW1i4q-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RXioileVidyy"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\":50257,       #Vocabulary size\n",
        "    \"context_length\":1024,    #Context length\n",
        "    \"emb_dim\":768,            #Embedding dimension\n",
        "    \"n_heads\":12,             #Number of attention heads\n",
        "    \"n_layers\":12,            #Number of layers\n",
        "    \"drop_rate\":0.1,          #Dropout rate\n",
        "    \"qkv_bias\":False,         #Query-Key-Value bias\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT Architecture Part 1: Dummy GPT Model Class"
      ],
      "metadata": {
        "id": "sgxUjsQCjvYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Use a placeholder for Transformer Block\n",
        "\n",
        "Step 2: Use a placeholder for LayerNorm"
      ],
      "metadata": {
        "id": "gObTVsTYj2R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "8u59_eiIj1do"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DummyGPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "        #Use a placeholder for TransformerBlock\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        #Use a placeholder for LayerNorm\n",
        "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"],bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "class DummyTransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        #A Simple placeholder\n",
        "\n",
        "    def forward(self, x):\n",
        "      #This block does nothing and just returns its input.\n",
        "        return x\n",
        "\n",
        "\n",
        "class DummyLayerNorm(nn.Module):\n",
        "    def __init__(self, dim, eps=1e-5):\n",
        "        super().__init__()\n",
        "        # The parameters here are just to mimic the LayerNorm interface.\n",
        "\n",
        "    def forward(self, x):\n",
        "        # This block does nothing and just returns its input.\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "LVeovUtVkCRF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 1: TOKENIZATION"
      ],
      "metadata": {
        "id": "JmutuHv5nD1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "batch = []\n",
        "txt1 = \"Every effort moves you\"\n",
        "txt2 = \"Every day holds a\"\n",
        "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
        "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
        "batch = torch.stack(batch,dim=0)\n",
        "print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMq-0g48nDPz",
        "outputId": "aff5ed93-3ab0-4e3d-fc30-56087bade2ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6109, 3626, 6100,  345],\n",
            "        [6109, 1110, 6622,  257]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 2: CREATE AN INSTANCE OF DUMMYGPT MODEL"
      ],
      "metadata": {
        "id": "ScWO6GcqnmOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = DummyGPTModel(GPT_CONFIG_124M)\n",
        "logits = model(batch)\n",
        "print(\"Output shape:\",logits.shape)\n",
        "print(logits)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byLADkJwncR8",
        "outputId": "c1b3ac48-4273-47fc-d623-938f9f40c26b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([2, 4, 50257])\n",
            "tensor([[[-0.9289,  0.2748, -0.7557,  ..., -1.6070,  0.2702, -0.5888],\n",
            "         [-0.4476,  0.1726,  0.5354,  ..., -0.3932,  1.5285,  0.8557],\n",
            "         [ 0.5680,  1.6053, -0.2155,  ...,  1.1624,  0.1380,  0.7425],\n",
            "         [ 0.0447,  2.4787, -0.8843,  ...,  1.3219, -0.0864, -0.5856]],\n",
            "\n",
            "        [[-1.5474, -0.0542, -1.0571,  ..., -1.8061, -0.4494, -0.6747],\n",
            "         [-0.8422,  0.8243, -0.1098,  ..., -0.1434,  0.2079,  1.2046],\n",
            "         [ 0.1355,  1.1858, -0.1453,  ...,  0.0869, -0.1590,  0.1552],\n",
            "         [ 0.1666, -0.8138,  0.2307,  ...,  2.5035, -0.3055, -0.3083]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output tensor has two rows corresponding to the two text samples. Each text sample consists of 4 tokens, each token is a 50,257-dimensional vector, which matches the size of the tokenizer's vocabulary.\n",
        "\n",
        "The embedding has 50,257 dimensions because each of these dimensions refers to a unique token in the vocabulary. At the end of this chapter, when we implement the post processing code, we will convert these 50,257 dimensional vectors back into token IDs, which we can then decode into words"
      ],
      "metadata": {
        "id": "FuBDzrQNvxCh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6HZ7xwbvvof_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}